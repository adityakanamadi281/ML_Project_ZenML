# Price Prediction ML System - Architecture Design

## ğŸ—ï¸ System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Price Prediction ML System                  â”‚
â”‚                         (ZenML Orchestration)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
   â”‚  Data   â”‚          â”‚  Feature  â”‚         â”‚   Model   â”‚
   â”‚Ingestionâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚Engineeringâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Training  â”‚
   â”‚  Step   â”‚          â”‚   Step    â”‚         â”‚   Step    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
        â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”             â”‚
        â”‚              â”‚ Preprocessing â”‚             â”‚
        â”‚              â”‚     Step      â”‚             â”‚
        â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
        â”‚                                            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  Evaluation  â”‚
                      â”‚     Step     â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  Prediction  â”‚
                      â”‚     Step     â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Component Design

### 1. Data Layer

#### Data Ingestion (`data_ingestion.py`)
- **Purpose**: Load raw data from source
- **Input**: Configuration file path
- **Output**: Raw pandas DataFrame
- **Responsibilities**:
  - Read data from configured source (CSV, database, API)
  - Validate data structure
  - Log data statistics

#### Data Preprocessing (`data_preprocessing.py`)
- **Purpose**: Clean and prepare data
- **Input**: Raw DataFrame
- **Output**: Features DataFrame, Target DataFrame
- **Responsibilities**:
  - Handle missing values
  - Detect and handle outliers
  - Separate features and target
  - Data type validation

### 2. Feature Engineering Layer

#### Feature Engineering (`feature_engineering.py`)
- **Purpose**: Transform features for model consumption
- **Input**: Features DataFrame, Target DataFrame
- **Output**: Engineered Features, Target, Preprocessor Artifacts
- **Responsibilities**:
  - Categorical encoding (Label Encoding)
  - Numerical scaling (StandardScaler)
  - Feature creation (if needed)
  - Save transformers for inference
- **Artifacts**:
  - `artifacts/scaler.pkl` - StandardScaler for numerical features
  - `artifacts/label_encoders.pkl` - LabelEncoders for categorical features

### 3. Model Layer

#### Model Training (`model_training.py`)
- **Purpose**: Train price prediction model
- **Input**: Engineered Features, Target
- **Output**: Trained Model, Training Metrics
- **Responsibilities**:
  - Split data (train/test)
  - Select and train model algorithm
  - Evaluate on test set
  - Save trained model
- **Supported Algorithms**:
  - Random Forest Regressor
  - Gradient Boosting Regressor
  - Linear Regression
- **Output Artifacts**:
  - `models/{model_name}_{version}.joblib` - Trained model

#### Model Evaluation (`model_evaluation.py`)
- **Purpose**: Comprehensive model evaluation
- **Input**: Trained Model, Features, Target, Metrics
- **Output**: Enhanced Metrics Dictionary
- **Responsibilities**:
  - Generate evaluation plots
  - Calculate additional metrics
  - Visualize predictions vs actuals
  - Residual analysis
- **Output Artifacts**:
  - `reports/plots/actual_vs_predicted.png`
  - `reports/plots/residuals.png`

### 4. Inference Layer

#### Prediction (`prediction.py`)
- **Purpose**: Make predictions on new data
- **Input**: Features DataFrame
- **Output**: Predictions DataFrame
- **Responsibilities**:
  - Load trained model
  - Apply feature transformations
  - Generate predictions
  - Format output

## ğŸ”„ Pipeline Flows

### Training Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Config File  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Ingestion  â”‚ â”€â”€â–¶ Raw DataFrame
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessing    â”‚ â”€â”€â–¶ Cleaned Features + Target
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature          â”‚ â”€â”€â–¶ Engineered Features + Artifacts
â”‚ Engineering      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Training   â”‚ â”€â”€â–¶ Trained Model + Metrics
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Evaluation       â”‚ â”€â”€â–¶ Final Metrics + Plots
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Inference Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ New Data     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessing   â”‚ â”€â”€â–¶ Cleaned Features
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature          â”‚ â”€â”€â–¶ Engineered Features
â”‚ Engineering      â”‚     (using saved transformers)
â”‚ (Inference Mode) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prediction      â”‚ â”€â”€â–¶ Predictions DataFrame
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—‚ï¸ Data Flow

### Training Phase

```
Raw Data (CSV)
    â”‚
    â”œâ”€â–¶ Data Ingestion
    â”‚       â”‚
    â”‚       â””â”€â–¶ Raw DataFrame
    â”‚
    â”œâ”€â–¶ Preprocessing
    â”‚       â”‚
    â”‚       â”œâ”€â–¶ Features DataFrame
    â”‚       â””â”€â–¶ Target DataFrame
    â”‚
    â”œâ”€â–¶ Feature Engineering
    â”‚       â”‚
    â”‚       â”œâ”€â–¶ Engineered Features
    â”‚       â”œâ”€â–¶ Scaler (saved)
    â”‚       â””â”€â–¶ Encoders (saved)
    â”‚
    â”œâ”€â–¶ Model Training
    â”‚       â”‚
    â”‚       â”œâ”€â–¶ Trained Model (saved)
    â”‚       â””â”€â–¶ Training Metrics
    â”‚
    â””â”€â–¶ Evaluation
            â”‚
            â”œâ”€â–¶ Evaluation Metrics
            â””â”€â–¶ Visualization Plots
```

### Inference Phase

```
New Data (CSV)
    â”‚
    â”œâ”€â–¶ Preprocessing
    â”‚       â”‚
    â”‚       â””â”€â–¶ Cleaned Features
    â”‚
    â”œâ”€â–¶ Feature Engineering
    â”‚       â”‚
    â”‚       â”œâ”€â–¶ Load Scaler
    â”‚       â”œâ”€â–¶ Load Encoders
    â”‚       â””â”€â–¶ Engineered Features
    â”‚
    â””â”€â–¶ Prediction
            â”‚
            â”œâ”€â–¶ Load Model
            â””â”€â–¶ Predictions (CSV)
```

## ğŸ”§ Configuration Management

### Configuration Structure

```yaml
data:
  source_path: "data/raw/prices.csv"
  processed_path: "data/processed/"
  features_path: "data/features/"

model:
  name: "price_predictor"
  version: "1.0.0"
  algorithm: "random_forest"

training:
  test_size: 0.2
  validation_size: 0.1
  random_state: 42
  cv_folds: 5

features:
  target_column: "price"
  categorical_features: []
  numerical_features: []
  date_features: []

evaluation:
  metrics: ["mse", "rmse", "mae", "r2_score"]
  save_plots: true
  plots_path: "reports/plots/"
```

### Configuration Benefits

- **Centralized**: All settings in one place
- **Versioned**: Track configuration changes
- **Flexible**: Easy to switch algorithms, adjust parameters
- **Reproducible**: Same config = same results

## ğŸ“Š Artifact Management

### Artifacts Produced

1. **Models**
   - Location: `models/{model_name}_{version}.joblib`
   - Format: Joblib serialized model
   - Versioned: Yes (via version in config)

2. **Preprocessors**
   - Location: `artifacts/scaler.pkl`, `artifacts/label_encoders.pkl`
   - Format: Pickle serialized transformers
   - Purpose: Ensure consistent transformations in inference

3. **Visualizations**
   - Location: `reports/plots/`
   - Formats: PNG images
   - Types: Actual vs Predicted, Residual plots

4. **Predictions**
   - Location: `predictions.csv`
   - Format: CSV with predicted prices

## ğŸ¯ Design Principles

### 1. Modularity
- Each step is independent and testable
- Easy to swap components
- Clear separation of concerns

### 2. Reproducibility
- Fixed random seeds
- Versioned models and configs
- Saved transformers ensure consistent preprocessing

### 3. Scalability
- ZenML handles orchestration
- Can easily add new steps
- Supports distributed execution

### 4. Maintainability
- Clear code structure
- Comprehensive documentation
- Type hints and schemas

### 5. Extensibility
- Easy to add new algorithms
- Simple to add new features
- Configurable without code changes

## ğŸ”„ Extension Points

### Adding New Algorithms

1. Import model in `model_training.py`
2. Add condition in algorithm selection
3. Update config with new algorithm name

### Adding New Preprocessing Steps

1. Add step in `data_preprocessing.py`
2. Ensure output format compatibility
3. Update documentation

### Adding New Features

1. Modify `feature_engineering.py`
2. Add feature creation logic
3. Update config if needed

### Adding Monitoring

1. Integrate with ZenML experiment tracking
2. Add logging to each step
3. Set up model performance monitoring

## ğŸš€ Deployment Considerations

### Current Architecture Supports

- âœ… Local development and testing
- âœ… Model versioning
- âœ… Reproducible pipelines
- âœ… Batch inference

### Future Enhancements

- ğŸ”„ Real-time inference API
- ğŸ”„ Model serving (MLflow, Seldon)
- ğŸ”„ A/B testing framework
- ğŸ”„ Automated retraining
- ğŸ”„ Data drift detection
- ğŸ”„ Model monitoring dashboard

## ğŸ“ˆ Performance Considerations

### Training
- Model selection based on data size
- Cross-validation for robust evaluation
- Feature importance analysis for optimization

### Inference
- Cached transformers (loaded once)
- Efficient model loading
- Batch processing support

## ğŸ”’ Best Practices Implemented

1. **Data Validation**: Schema validation with Pydantic
2. **Error Handling**: Graceful error messages
3. **Logging**: Comprehensive logging at each step
4. **Documentation**: Inline and external docs
5. **Version Control**: Model and config versioning
6. **Testing Ready**: Modular design enables unit testing

